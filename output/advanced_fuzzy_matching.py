#!/usr/bin/env python3
"""
Advanced Fuzzy Matching Ñ rapidfuzz Ð¸ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÐµÐ¹
- Rapidfuzz Ð´Ð»Ñ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚Ð¸ (10-15x faster)
- Ð­ÐºÑÑ‚Ñ€Ð°ÐºÑ†Ð¸Ñ quality tags (SD/HD/UHD/4K)
- Ð­ÐºÑÑ‚Ñ€Ð°ÐºÑ†Ð¸Ñ country codes
- ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¸Ð¼Ñ‘Ð½ ÐºÐ°Ð½Ð°Ð»Ð¾Ð²
"""

import json
import sqlite3
import re
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
import time

try:
    from rapidfuzz import fuzz, process
except ImportError:
    print("ERROR: rapidfuzz Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½")
    print("Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸: uv pip install rapidfuzz")
    exit(1)

print("=" * 70)
print("ADVANCED FUZZY MATCHING")
print("=" * 70)
print()

# === ÐŸÐ°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ð´Ð»Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ===

# Quality tags
QUALITY_PATTERNS = [
    r'\b(SD|HD|FHD|UHD|4K|8K)\b',
    r'\b(\d{3,4}p)\b',  # 720p, 1080p, 2160p
    r'\bHEVC\b',
]

# Country codes (ISO 3166-1)
COUNTRY_PATTERNS = [
    r'\b([A-Z]{2})\b',  # US, UK, RU, DE, etc.
    r'\(([A-Z]{2})\)',  # (US), (UK)
    r'\[([A-Z]{2})\]',  # [US], [UK]
]

# Common channel suffixes to remove
SUFFIXES = [
    r'\bTV\b',
    r'\bHD\b',
    r'\bPlus\b',
    r'\b\+\b',
    r'\bChannel\b',
]

@dataclass
class ChannelInfo:
    """Ð Ð°ÑÐ¿Ð°Ñ€ÑÐµÐ½Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ ÐºÐ°Ð½Ð°Ð»Ðµ."""
    name: str
    normalized_name: str
    quality: Optional[str] = None
    country: Optional[str] = None
    original_name: str = ""

def extract_quality(name: str) -> Tuple[str, Optional[str]]:
    """
    Ð˜Ð·Ð²Ð»ÐµÑ‡ÑŒ quality tag Ð¸Ð· Ð¸Ð¼ÐµÐ½Ð¸.
    
    Returns:
        (cleaned_name, quality)
    """
    quality = None
    
    for pattern in QUALITY_PATTERNS:
        match = re.search(pattern, name, re.IGNORECASE)
        if match:
            quality = match.group(1).upper()
            name = re.sub(pattern, '', name, flags=re.IGNORECASE)
            break
    
    return name.strip(), quality

def extract_country(name: str) -> Tuple[str, Optional[str]]:
    """
    Ð˜Ð·Ð²Ð»ÐµÑ‡ÑŒ country code Ð¸Ð· Ð¸Ð¼ÐµÐ½Ð¸.
    
    Returns:
        (cleaned_name, country)
    """
    country = None
    
    for pattern in COUNTRY_PATTERNS:
        match = re.search(pattern, name)
        if match:
            potential_country = match.group(1)
            
            # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ Ð»Ð¾Ð¶Ð½Ñ‹Ðµ ÑÑ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°Ð½Ð¸Ñ (Ð¾Ð±Ñ‰Ð¸Ðµ ÑÐ¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð¸Ñ)
            false_positives = {'TV', 'HD', 'SD', 'FM', 'AM', 'BR', 'LA'}
            if potential_country not in false_positives:
                country = potential_country
                name = re.sub(pattern, '', name)
                break
    
    return name.strip(), country

def normalize_name(name: str) -> str:
    """
    ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸Ð¼Ñ ÐºÐ°Ð½Ð°Ð»Ð° Ð´Ð»Ñ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ.
    
    - Lowercase
    - Remove quality tags
    - Remove country codes
    - Remove common suffixes
    - Remove extra spaces/punctuation
    """
    # Lowercase
    name = name.lower()
    
    # Extract and remove quality
    name, _ = extract_quality(name)
    
    # Extract and remove country
    name, _ = extract_country(name)
    
    # Remove common suffixes
    for suffix in SUFFIXES:
        name = re.sub(suffix, '', name, flags=re.IGNORECASE)
    
    # Remove special chars (except spaces)
    name = re.sub(r'[^\w\s]', '', name)
    
    # Normalize spaces
    name = re.sub(r'\s+', ' ', name)
    
    return name.strip()

def parse_channel(name: str) -> ChannelInfo:
    """ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³ ÐºÐ°Ð½Ð°Ð»Ð°."""
    original = name
    
    # Extract quality
    name, quality = extract_quality(name)
    
    # Extract country
    name, country = extract_country(name)
    
    # Normalize
    normalized = normalize_name(original)
    
    return ChannelInfo(
        name=name.strip(),
        normalized_name=normalized,
        quality=quality,
        country=country,
        original_name=original
    )

# === Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… ===

print("[1/4] Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° IPTVPortal ÐºÐ°Ð½Ð°Ð»Ð¾Ð²...")

portal_dump_path = Path("output/tv_channel_full_dump.json")

if not portal_dump_path.exists():
    print(f"ERROR: {portal_dump_path} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½")
    exit(1)

with open(portal_dump_path, 'r', encoding='utf-8') as f:
    portal_data = json.load(f)

portal_channels = portal_data['records']
print(f"  âœ“ Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾: {len(portal_channels):,} ÐºÐ°Ð½Ð°Ð»Ð¾Ð²")
print()

# ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð¸ ÑÐ¾Ð·Ð´Ð°Ñ‘Ð¼ Ð¸Ð½Ð´ÐµÐºÑ
print("  Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¸Ð½Ð´ÐµÐºÑÐ° Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÐµÐ¹...")

portal_parsed = []
portal_index = {}

for ch in portal_channels:
    name = ch.get('name', '')
    if not name:
        continue
    
    parsed = parse_channel(name)
    parsed_data = {
        'id': ch['id'],
        'original_name': name,
        'parsed': parsed,
        'raw': ch
    }
    
    portal_parsed.append(parsed_data)
    portal_index[parsed.normalized_name] = parsed_data

print(f"  âœ“ Ð˜Ð½Ð´ÐµÐºÑ ÑÐ¾Ð·Ð´Ð°Ð½: {len(portal_index):,} ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð¼Ñ‘Ð½")
print()

# ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð°
print("  ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸:")
examples = [
    "BBC One HD (UK)",
    "CNN US 1080p",
    "RT Documentary UHD",
    "Discovery Channel 4K",
    "Fox Sports+ HD"
]

for ex in examples:
    parsed = parse_channel(ex)
    print(f"    {ex:30s} â†’ {parsed.normalized_name:20s} | Q:{parsed.quality or 'None':4s} | C:{parsed.country or 'None'}")

print()

# === Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÐºÐ°Ð½Ð°Ð»Ð¾Ð² ===

print("[2/4] Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÐºÐ°Ð½Ð°Ð»Ð¾Ð²...")

db_path = Path("output/iptv_full.db")

if not db_path.exists():
    print(f"WARNING: {db_path} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ mock Ð´Ð°Ð½Ð½Ñ‹Ðµ")
    
    local_channels = [
        {'id': 'bbc1.uk', 'name': 'BBC One HD', 'country': 'GB', 'stream_count': 10},
        {'id': 'cnn.us', 'name': 'CNN', 'country': 'US', 'stream_count': 8},
        {'id': 'rt.ru', 'name': 'RT Documentary', 'country': 'RU', 'stream_count': 5},
    ]
else:
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT 
            c.id, c.name, c.alt_names, c.country, 
            c.categories, c.logo_url,
            COUNT(s.id) as stream_count
        FROM channels c
        LEFT JOIN streams s ON c.id = s.channel_id
        WHERE s.url IS NOT NULL
        GROUP BY c.id
        HAVING stream_count > 0
        ORDER BY stream_count DESC
    """)
    
    local_channels = [dict(row) for row in cursor.fetchall()]
    conn.close()

print(f"  âœ“ Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾: {len(local_channels):,} ÐºÐ°Ð½Ð°Ð»Ð¾Ð²")
print()

# ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ ÐºÐ°Ð½Ð°Ð»Ñ‹
print("  ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÐºÐ°Ð½Ð°Ð»Ð¾Ð²...")

local_parsed = []

for ch in local_channels:
    parsed = parse_channel(ch['name'])
    local_parsed.append({
        'id': ch['id'],
        'original_name': ch['name'],
        'parsed': parsed,
        'raw': ch
    })

print(f"  âœ“ Ð Ð°ÑÐ¿Ð°Ñ€ÑÐµÐ½Ð¾: {len(local_parsed):,} ÐºÐ°Ð½Ð°Ð»Ð¾Ð²")
print()

# === Fuzzy Matching ===

print("[3/4] Fuzzy Matching Ñ rapidfuzz...")
print()

def calculate_match_score(local_ch: dict, portal_ch: dict) -> float:
    """
    Ð Ð°ÑÑÑ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ score matching.
    
    ÐšÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹:
    - Name similarity: 70%
    - Country match: 20%
    - Quality match: 10%
    """
    local_parsed = local_ch['parsed']
    portal_parsed = portal_ch['parsed']
    
    # Name similarity (rapidfuzz)
    name_score = fuzz.token_sort_ratio(
        local_parsed.normalized_name,
        portal_parsed.normalized_name
    ) / 100.0
    
    # Country match
    country_score = 0.0
    if local_parsed.country and portal_parsed.country:
        country_score = 1.0 if local_parsed.country == portal_parsed.country else 0.0
    elif not local_parsed.country and not portal_parsed.country:
        country_score = 0.5  # ÐžÐ±Ð° Ð±ÐµÐ· ÐºÐ¾Ð´Ð° - ÑÑ€ÐµÐ´Ð½Ð¸Ð¹ Ð±Ð°Ð»Ð»
    
    # Quality match
    quality_score = 0.0
    if local_parsed.quality and portal_parsed.quality:
        quality_score = 1.0 if local_parsed.quality == portal_parsed.quality else 0.0
    elif not local_parsed.quality and not portal_parsed.quality:
        quality_score = 0.5
    
    # Weighted sum
    total_score = (
        name_score * 0.7 +
        country_score * 0.2 +
        quality_score * 0.1
    )
    
    return total_score

matches = []
no_matches = []
start_time = time.time()

total = len(local_parsed)
checkpoint = max(1, total // 20)

print(f"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° {total:,} ÐºÐ°Ð½Ð°Ð»Ð¾Ð²...")
print()

for i, local_ch in enumerate(local_parsed, 1):
    # Progress
    if i % checkpoint == 0 or i == 1:
        elapsed = time.time() - start_time
        rate = i / elapsed if elapsed > 0 else 0
        eta = (total - i) / rate if rate > 0 else 0
        progress = (i / total) * 100
        
        print(f"  [{i:,}/{total:,}] {progress:.1f}% | "
              f"Rate: {rate:.0f} ch/s | "
              f"ETA: {eta:.1f}s")
    
    local_parsed_data = local_ch['parsed']
    
    # 1. Exact match Ð² Ð¸Ð½Ð´ÐµÐºÑÐµ
    exact_match = portal_index.get(local_parsed_data.normalized_name)
    
    if exact_match:
        # Exact match
        match = {
            'local_id': local_ch['id'],
            'local_name': local_ch['original_name'],
            'local_normalized': local_parsed_data.normalized_name,
            'local_quality': local_parsed_data.quality,
            'local_country': local_parsed_data.country,
            'portal_id': exact_match['id'],
            'portal_name': exact_match['original_name'],
            'portal_normalized': exact_match['parsed'].normalized_name,
            'portal_quality': exact_match['parsed'].quality,
            'portal_country': exact_match['parsed'].country,
            'confidence': 1.0,
            'match_type': 'exact',
            'stream_count': local_ch['raw'].get('stream_count', 0)
        }
        matches.append(match)
    else:
        # 2. Rapidfuzz search
        # Ð“Ð¾Ñ‚Ð¾Ð²Ð¸Ð¼ ÑÐ¿Ð¸ÑÐ¾Ðº Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ°
        choices = [(ch['parsed'].normalized_name, ch) for ch in portal_parsed]
        
        # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ñ‚Ð¾Ð¿-1 Ñ rapidfuzz
        result = process.extractOne(
            local_parsed_data.normalized_name,
            choices,
            scorer=fuzz.token_sort_ratio,
            score_cutoff=60  # ÐœÐ¸Ð½Ð¸Ð¼ÑƒÐ¼ 60%
        )
        
        if result:
            matched_name, best_portal, base_score = result[0], result[1], result[2] / 100.0
            
            # Ð Ð°ÑÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ score
            total_score = calculate_match_score(local_ch, best_portal)
            
            if total_score >= 0.6:  # ÐŸÐ¾Ñ€Ð¾Ð³ 60%
                match = {
                    'local_id': local_ch['id'],
                    'local_name': local_ch['original_name'],
                    'local_normalized': local_parsed_data.normalized_name,
                    'local_quality': local_parsed_data.quality,
                    'local_country': local_parsed_data.country,
                    'portal_id': best_portal['id'],
                    'portal_name': best_portal['original_name'],
                    'portal_normalized': best_portal['parsed'].normalized_name,
                    'portal_quality': best_portal['parsed'].quality,
                    'portal_country': best_portal['parsed'].country,
                    'confidence': total_score,
                    'match_type': 'fuzzy',
                    'stream_count': local_ch['raw'].get('stream_count', 0),
                    'name_score': base_score,
                    'country_match': local_parsed_data.country == best_portal['parsed'].country if local_parsed_data.country and best_portal['parsed'].country else None,
                    'quality_match': local_parsed_data.quality == best_portal['parsed'].quality if local_parsed_data.quality and best_portal['parsed'].quality else None
                }
                matches.append(match)
            else:
                no_matches.append({
                    'id': local_ch['id'],
                    'name': local_ch['original_name'],
                    'stream_count': local_ch['raw'].get('stream_count', 0),
                    'best_score': total_score
                })
        else:
            no_matches.append({
                'id': local_ch['id'],
                'name': local_ch['original_name'],
                'stream_count': local_ch['raw'].get('stream_count', 0),
                'best_score': 0.0
            })

elapsed_total = time.time() - start_time

print()
print(f"âœ“ Matching Ð·Ð°Ð²ÐµÑ€ÑˆÑ‘Ð½ Ð·Ð° {elapsed_total:.1f} ÑÐµÐº ({elapsed_total/60:.1f} Ð¼Ð¸Ð½)")
print()

# === Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ ===

print("[4/4] Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²...")
print()

results_json = {
    'total_local': len(local_parsed),
    'total_portal': len(portal_parsed),
    'matched': len(matches),
    'unmatched': len(no_matches),
    'match_rate': len(matches) / len(local_parsed) * 100 if local_parsed else 0,
    'processing_time_sec': elapsed_total,
    'processing_speed': len(local_parsed) / elapsed_total if elapsed_total > 0 else 0,
    'matches': matches,
    'no_matches': no_matches[:100]
}

with open('output/matching_results.json', 'w', encoding='utf-8') as f:
    json.dump(results_json, f, indent=2, ensure_ascii=False)

print(f"  âœ“ JSON: output/matching_results.json")
print()

# Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð² SQLite (ÐµÑÐ»Ð¸ Ð±Ð°Ð·Ð° ÐµÑÑ‚ÑŒ)
if db_path.exists():
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS matched_channels (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            local_id TEXT NOT NULL,
            local_name TEXT NOT NULL,
            local_normalized TEXT,
            local_quality TEXT,
            local_country TEXT,
            portal_id INTEGER,
            portal_name TEXT,
            portal_normalized TEXT,
            portal_quality TEXT,
            portal_country TEXT,
            confidence REAL,
            match_type TEXT,
            stream_count INTEGER,
            created_at TEXT DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(local_id, portal_id)
        )
    """)
    
    # Ð˜Ð½Ð´ÐµÐºÑÑ‹
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_confidence ON matched_channels(confidence)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_match_type ON matched_channels(match_type)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_quality ON matched_channels(local_quality, portal_quality)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_country ON matched_channels(local_country, portal_country)")
    
    # Ð’ÑÑ‚Ð°Ð²ÐºÐ°
    for match in matches:
        cursor.execute("""
            INSERT OR REPLACE INTO matched_channels
            (local_id, local_name, local_normalized, local_quality, local_country,
             portal_id, portal_name, portal_normalized, portal_quality, portal_country,
             confidence, match_type, stream_count)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            match['local_id'],
            match['local_name'],
            match['local_normalized'],
            match['local_quality'],
            match['local_country'],
            match['portal_id'],
            match['portal_name'],
            match['portal_normalized'],
            match['portal_quality'],
            match['portal_country'],
            match['confidence'],
            match['match_type'],
            match['stream_count']
        ))
    
    conn.commit()
    conn.close()
    
    print(f"  âœ“ SQLite: output/iptv_full.db (Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° matched_channels)")
    print()

# === Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ===

print("=" * 70)
print("Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð«")
print("=" * 70)
print()

print(f"Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ ÐºÐ°Ð½Ð°Ð»Ñ‹:  {len(local_parsed):,}")
print(f"IPTVPortal ÐºÐ°Ð½Ð°Ð»Ñ‹: {len(portal_parsed):,}")
print()

print(f"Ð¡Ð¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ:        {len(matches):,} ({len(matches)/len(local_parsed)*100:.1f}%)")
print(f"ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾:        {len(no_matches):,} ({len(no_matches)/len(local_parsed)*100:.1f}%)")
print()

print(f"Ð¡ÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ:          {results_json['processing_speed']:.0f} ÐºÐ°Ð½Ð°Ð»Ð¾Ð²/ÑÐµÐº")
print(f"Ð’Ñ€ÐµÐ¼Ñ:             {elapsed_total:.1f} ÑÐµÐº ({elapsed_total/60:.1f} Ð¼Ð¸Ð½)")
print()

# ÐŸÐ¾ Ñ‚Ð¸Ð¿Ð°Ð¼
exact = [m for m in matches if m['match_type'] == 'exact']
fuzzy = [m for m in matches if m['match_type'] == 'fuzzy']

print(f"Exact matches:     {len(exact):,}")
print(f"Fuzzy matches:     {len(fuzzy):,}")
print()

# ÐŸÐ¾ confidence
high = [m for m in matches if m['confidence'] >= 0.9]
medium = [m for m in matches if 0.7 <= m['confidence'] < 0.9]
low = [m for m in matches if m['confidence'] < 0.7]

print("Confidence breakdown:")
print(f"  Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ (â‰¥90%):  {len(high):,} ({len(high)/len(matches)*100:.1f}%)")
print(f"  Ð¡Ñ€ÐµÐ´Ð½ÑÑ (70-89%): {len(medium):,} ({len(medium)/len(matches)*100:.1f}%)")
print(f"  ÐÐ¸Ð·ÐºÐ°Ñ (<70%):   {len(low):,} ({len(low)/len(matches)*100:.1f}%)")
print()

# Quality extraction stats
with_quality = [m for m in matches if m['local_quality'] or m['portal_quality']]
quality_match = [m for m in matches if m['local_quality'] and m['portal_quality'] and m['local_quality'] == m['portal_quality']]

print("Quality tags:")
print(f"  Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¾:       {len(with_quality):,}")
print(f"  Ð¡Ð¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹:      {len(quality_match):,}")
print()

# Country extraction stats
with_country = [m for m in matches if m['local_country'] or m['portal_country']]
country_match = [m for m in matches if m['local_country'] and m['portal_country'] and m['local_country'] == m['portal_country']]

print("Country codes:")
print(f"  Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¾:       {len(with_country):,}")
print(f"  Ð¡Ð¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹:      {len(country_match):,}")
print()

# Ð¢Ð¾Ð¿-20 ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹
print("Ð¢Ð¾Ð¿-10 ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹:")
print()

sorted_matches = sorted(matches, key=lambda x: (x['confidence'], x['stream_count']), reverse=True)

for i, m in enumerate(sorted_matches[:10], 1):
    quality_str = f"Q:{m['local_quality'] or '?'}â†’{m['portal_quality'] or '?'}" if m['local_quality'] or m['portal_quality'] else ""
    country_str = f"C:{m['local_country'] or '?'}â†’{m['portal_country'] or '?'}" if m['local_country'] or m['portal_country'] else ""
    
    print(f"{i:2d}. {m['local_name']}")
    print(f"    â†’ {m['portal_name']}")
    print(f"    Conf: {m['confidence']:.2%} | Type: {m['match_type']} | {quality_str} | {country_str}")
    print()

print("=" * 70)
print("âœ… Ð“Ð¾Ñ‚Ð¾Ð²Ð¾!")
print()
print("Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹:")
print("  ðŸ“Š output/matching_results.json")
print("  ðŸ“Š output/iptv_full.db (Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° matched_channels)")
print()
print("SQL Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹:")
print("  sqlite3 output/iptv_full.db")
print('  > SELECT local_name, portal_name, confidence, local_quality, portal_quality')
print('    FROM matched_channels WHERE confidence > 0.9 LIMIT 10;')
